import streamlit as st
import time
from agent_core import BlockchainAgent

# åœ¨ Sidebar æˆ– Main Page é¡¯ç¤ºç‹€æ…‹æ©Ÿ
st.sidebar.markdown("### Agent å…§éƒ¨ç‹€æ…‹æ©Ÿ (FSM)")

# ä½¿ç”¨ Graphviz å®šç¾©ç‹€æ…‹æ©Ÿ
fsm_graph = """
digraph G {
    // è¨­å®šåœ–è¡¨æ–¹å‘èˆ‡å±¬æ€§
    rankdir=LR;
    node [shape=circle, style=filled, color=lightblue, fontname="Helvetica"];
    edge [fontname="Helvetica", fontsize=10];

    // å®šç¾©ç‹€æ…‹ç¯€é»
    IDLE [label="IDLE\n(å¾…æ©Ÿ)", shape=doublecircle, color=lightgrey];
    CLASSIFY [label="CLASSIFY\nINTENT", shape=box, color=gold];
    
    // çŸ¥è­˜å•ç­”åˆ†æ”¯
    RAG [label="RAG\nRETRIEVAL", color=lightgreen];
    GEN_ANS [label="GENERATING\nANSWER", color=lightgreen];
    
    // éŒ¢åŒ…åˆ†æåˆ†æ”¯
    FETCH [label="FETCHING\nCHAIN DATA", color=salmon];
    ANALYSIS [label="ANALYZING\nDATA", color=salmon];
    
    // ä¸€èˆ¬é–’èŠåˆ†æ”¯
    CHAT [label="CHATTING", color=lightyellow];

    // å®šç¾©è½‰ç§»è·¯å¾‘ (Transitions)
    IDLE -> CLASSIFY [label="User Input"];
    
    CLASSIFY -> RAG [label="Intent: KNOWLEDGE_QA"];
    RAG -> GEN_ANS [label="Context Found"];
    GEN_ANS -> IDLE [label="Response Streamed"];
    
    CLASSIFY -> FETCH [label="Intent: WALLET_ANALYSIS"];
    FETCH -> ANALYSIS [label="API Data Ready"];
    ANALYSIS -> IDLE [label="Response Streamed"];
    
    CLASSIFY -> CHAT [label="Intent: GENERAL_CHAT"];
    CHAT -> IDLE [label="Response Streamed"];
}
"""

# æ¸²æŸ“åœ–è¡¨
st.sidebar.graphviz_chart(fsm_graph)
st.markdown("### ç³»çµ±æ¶æ§‹è³‡æ–™æµ (DAG)")

dag_graph = """
digraph DAG {
    rankdir=TB;
    node [shape=box, style=rounded, fontname="Helvetica"];

    // å®šç¾©ç¯€é»
    User [label="User Input", shape=ellipse, style=filled, color=lightgrey];
    Classifier [label="Intent Classifier\n(Regex/Keyword)", color=gold];
    
    subgraph cluster_tools {
        label = "External Tools";
        style = dashed;
        color = grey;
        
        Moralis [label="Moralis Multi-Chain API\n(Parallel Threads)", color=salmon];
        RAG [label="RAG Engine\n(ChromaDB + Embedding)", color=lightgreen];
    }
    
    PromptEng [label="Prompt Engineering\n(Context + Data Aggregation)"];
    LLM [label="LLM Inference\n(gpt-oss:120b)", style=filled, color=lightblue];
    StreamUI [label="Streamlit UI\n(Streaming Output)", shape=ellipse, style=filled, color=lightgrey];

    // å®šç¾©è³‡æ–™æµå‘
    User -> Classifier;
    
    Classifier -> Moralis [label="Address/Wallet"];
    Classifier -> RAG [label="Question/Concept"];
    Classifier -> PromptEng [label="Chat History"];
    
    Moralis -> PromptEng [label="Portfolio JSON"];
    RAG -> PromptEng [label="Retrieved Chunks"];
    
    PromptEng -> LLM [label="Final Prompt"];
    LLM -> StreamUI [label="Token Stream"];
}
"""

st.graphviz_chart(dag_graph)
# 1. åŸºæœ¬è¨­å®š
st.set_page_config(page_title="Blockchain AI Agent", layout="wide", page_icon="ğŸ›¡ï¸")

# 2. åˆå§‹åŒ– Agent
if "agent" not in st.session_state:
    st.session_state.agent = BlockchainAgent()
    st.session_state.messages = []

# Sidebar
st.sidebar.title("å€å¡ŠéˆåŠ©ç†")
st.sidebar.caption("NCKU Final Project Demo")
st.sidebar.info(
    """
    **Backend Status:**
    - Model: gpt-oss:120b
    - API: Moralis (Filtered)
    - Latency: High (School Server)
    """
)
if st.button("æ¸…é™¤å°è©±"):
    st.session_state.messages = []
    st.rerun()

# ä¸»æ¨™é¡Œ
st.title("å€å¡ŠéˆçŸ¥è­˜èˆ‡éŒ¢åŒ…åˆ†æ Agent")

# 3. é¡¯ç¤ºæ­·å²è¨Šæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# 4. è¼¸å…¥æ¡†èˆ‡é‚è¼¯
if user_input := st.chat_input("è¼¸å…¥å•é¡Œ (ä¾‹ï¼šæŸ¥ Vitalik éŒ¢åŒ…è³‡ç”¢ã€è§£é‡‹ ERC-721...)"):
    
    # é¡¯ç¤ºä½¿ç”¨è€…è¼¸å…¥
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)

    # Agent å›æ‡‰å€å¡Š
    with st.chat_message("assistant"):
        response_generator = None
        
        # ä½¿ç”¨ st.status é¡¯ç¤ºå¤šéšæ®µç‹€æ…‹
        with st.status("Agent æ­£åœ¨é‹ä½œä¸­...", expanded=True) as status:
            
            # éšæ®µ 1: æ„åœ–åˆ†æèˆ‡å·¥å…·å‘¼å«
            st.write("åˆ†æä½¿ç”¨è€…æ„åœ–...")
            time.sleep(0.5) 
            
            if "éŒ¢åŒ…" in user_input or "0x" in user_input or "Vitalik" in user_input or "è³‡ç”¢" in user_input:
                st.write("é€£ç·š Moralis API æƒæéˆä¸Šè³‡ç”¢...")
                st.write("åŸ·è¡Œè©é¨™ä»£å¹£éæ¿¾ (Anti-Spam Filter)...")
            elif "è§£é‡‹" or "ä»€éº¼" in user_input:
                st.write("æª¢ç´¢ RAG çŸ¥è­˜åº«...")
            
            # éšæ®µ 2: å‘¼å« LLM
            st.write("æ­£åœ¨æ’éšŠç­‰å¾…å­¸æ ¡ Server (gpt-oss:120b)... é€™å¯èƒ½éœ€è¦ 20-40 ç§’...")
            
            try:
                # çœŸæ­£çš„åŸ·è¡Œé»
                response_generator = st.session_state.agent.run(user_input)
                status.update(label="LLM é–‹å§‹ç”Ÿæˆå›æ‡‰", state="complete", expanded=False)
            except Exception as e:
                status.update(label="ç™¼ç”ŸéŒ¯èª¤", state="error")
                st.error(f"ç³»çµ±éŒ¯èª¤: {e}")

        # éšæ®µ 3: é¡¯ç¤ºçµæœ (Streaming)
        if response_generator:
            full_response = st.write_stream(response_generator)
            
            # å­˜å…¥æ­·å²
            st.session_state.messages.append({"role": "assistant", "content": full_response})